#openai_file_search_use.py
from openai import OpenAI
import os
from dotenv import load_dotenv

load_dotenv(override=True)

client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))

"""
Standalone vector search
---------------------------
Now that our vector store is ready, we are able to query the Vector 
Store directly and retrieve relevant content for a specific query. 
Using the new vector search API, we're able to find relevant items 
from our knowledge base without necessarily integrating it in an LLM query.

We can see that different size (and under-the-hood different texts) have been 
returned from the search query. They all have different relevancy score that 
are calculated by our ranker which uses hybrid search.
"""

vector_id = 'ENTER_YOUR_VECTOR_STORE_ID_HERE'

query = input("Enter your question to search the vector store: ")
search_results = client.vector_stores.search(
    vector_store_id=vector_id,
    query=query
)

for result in search_results.data:
    print(str(len(result.content[0].text)) + ' of character of content from ' + result.filename + ' with a relevant score of ' + str(result.score))


"""
Integrating search results with LLM in a single API call
========================================================
However instead of querying the vector store and then passing the data 
into the Responses or Chat Completion API call, an even more convenient 
way to use these search results in an LLM query would be to plug the use of the file_search 
tool as part of OpenAI Responses API.

What this allows us to do is take the relevant portions of our documents for the current input
generated by a user or for a specific task and supplement it with this most relevant information 
from our vector store. Integration into the API call allows us to simultaneously find this information 
and put it into the context of the current iteration of the LLM interaction alongside the input.
"""

query = input("Enter your question to search the vector store: ")
response = client.responses.create(
    input= query,
    model="gpt-4o-mini",
    tools=[{
        "type": "file_search",
        "vector_store_ids": [vector_id],
    }]
)

# Extract annotations from the response
annotations = response.output[1].content[0].annotations
    
# Get top-k retrieved filenames
retrieved_files = set([result.filename for result in annotations])

print(f'Files used: {retrieved_files}')
print('Response:')
print(response.output[1].content[0].text) # 0 being the filesearch call